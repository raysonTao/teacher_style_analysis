#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å‚è€ƒæ–‡çŒ®éªŒè¯è„šæœ¬
- ä» references_generated.bib ä¸­è§£ææ¯æ¡ \bibitem
- é€šè¿‡ Semantic Scholar API æŸ¥è¯¢è®ºæ–‡ï¼ˆè‹±æ–‡ï¼‰
- é€šè¿‡ CrossRef API ä½œä¸ºå¤‡ç”¨
- è®¡ç®—æ ‡é¢˜ç›¸ä¼¼åº¦éªŒè¯å¼•ç”¨å‡†ç¡®æ€§
- è¾“å‡ºéªŒè¯æŠ¥å‘Š references_verified.md
"""

import urllib.request
import urllib.parse
import json
import re
import time
import difflib
import os

# â”€â”€ è·¯å¾„é…ç½® â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
BASE_DIR = os.path.dirname(os.path.abspath(__file__))
BIB_FILE = os.path.join(BASE_DIR, "references_generated.bib")
OUT_BIB  = os.path.join(BASE_DIR, "references_verified.bib")
REPORT   = os.path.join(BASE_DIR, "verification_report.md")

# â”€â”€ ç›¸ä¼¼åº¦é˜ˆå€¼ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
THRESHOLD_PASS  = 0.80  # â‰¥80% è§†ä¸ºé€šè¿‡
THRESHOLD_WARN  = 0.55  # 55%~80% è­¦å‘Š
# <55% è§†ä¸ºå¤±è´¥ï¼ˆæœªæ‰¾åˆ°æˆ–ä¸åŒ¹é…ï¼‰

# â”€â”€ API å·¥å…· â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def http_get(url, headers=None, timeout=12):
    h = {"User-Agent": "RefVerifier/1.0 (academic research)"}
    if headers:
        h.update(headers)
    req = urllib.request.Request(url, headers=h)
    with urllib.request.urlopen(req, timeout=timeout) as resp:
        return json.loads(resp.read().decode("utf-8"))

def semantic_scholar_search(title, max_retries=4):
    """Search Semantic Scholar by title, return best match or None."""
    q = urllib.parse.quote(title[:200])
    url = (
        "https://api.semanticscholar.org/graph/v1/paper/search"
        f"?query={q}&limit=3"
        "&fields=title,authors,year,venue,journal,externalIds,publicationVenue"
    )
    for attempt in range(max_retries):
        try:
            data = http_get(url)
            if data.get("data"):
                return data["data"]  # list of candidates
        except urllib.error.HTTPError as e:
            if e.code == 429:
                wait = 8 * (attempt + 1)
                print(f"    [429] rate limit, wait {wait}s...")
                time.sleep(wait)
            else:
                print(f"    [HTTP {e.code}] {e}")
                break
        except Exception as e:
            print(f"    [ERR] {e}")
            break
    return None

def crossref_search(title, max_retries=3):
    """Search CrossRef by title, return best match or None."""
    q = urllib.parse.quote(title[:200])
    url = (
        "https://api.crossref.org/works"
        f"?query.title={q}&rows=3&select=title,author,published,container-title,DOI"
    )
    for attempt in range(max_retries):
        try:
            data = http_get(url, headers={"mailto": "student@ecnu.edu.cn"})
            items = data.get("message", {}).get("items", [])
            if items:
                return items
        except urllib.error.HTTPError as e:
            if e.code == 429:
                wait = 5 * (attempt + 1)
                print(f"    [CrossRef 429] wait {wait}s...")
                time.sleep(wait)
            else:
                break
        except Exception as e:
            print(f"    [CrossRef ERR] {e}")
            break
    return None

# â”€â”€ å­—ç¬¦ä¸²å·¥å…· â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def normalize(s):
    """Lowercase, strip punctuation/whitespace for comparison."""
    s = s.lower()
    s = re.sub(r"[^\w\s]", " ", s)
    s = re.sub(r"\s+", " ", s).strip()
    return s

def similarity(a, b):
    return difflib.SequenceMatcher(None, normalize(a), normalize(b)).ratio()

def best_match(candidates, query_title):
    """Return (best_item, score) from a list of candidates."""
    best, best_score = None, 0.0
    for c in candidates:
        t = c.get("title") or ""
        if isinstance(t, list):   # CrossRef returns list
            t = t[0] if t else ""
        s = similarity(query_title, t)
        if s > best_score:
            best, best_score = c, s
    return best, best_score

# â”€â”€ è§£æ .bib â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def parse_bib(path):
    """
    Parse \bibitem{key} ... entries.
    Returns list of dict: {key, raw, title_guess, is_chinese, is_todo}
    """
    with open(path, encoding="utf-8") as f:
        text = f.read()

    # Split on \bibitem boundaries
    parts = re.split(r"(?=\\bibitem\{)", text)
    entries = []
    for part in parts:
        part = part.strip()
        if not part.startswith(r"\bibitem"):
            continue
        m = re.match(r"\\bibitem\{([^}]+)\}\s*(.*)", part, re.DOTALL)
        if not m:
            continue
        key  = m.group(1).strip()
        body = m.group(2).strip()
        is_todo    = "% TODO" in body
        is_chinese = any('\u4e00' <= c <= '\u9fff' for c in body)

        # Guess title: for English, first quoted or italic segment, or 2nd sentence
        title_guess = ""
        if is_chinese:
            # Chinese: first Chinese phrase before [J] or period
            cm = re.search(r'[\u4e00-\u9fff][^\[ã€‚.]{5,60}', body)
            title_guess = cm.group(0).strip() if cm else ""
        else:
            # English: text inside \textit{...} if present
            tm = re.search(r'\\textit\{([^}]+)\}', body)
            if tm:
                pass  # that's venue, not title
            # Title is usually after "key} Author. (year). TITLE. venue"
            # Heuristic: sentence after "). "
            tm2 = re.search(r'\(\d{4}\)\.\s+(.+?)\.\s+\\textit', body, re.DOTALL)
            if tm2:
                title_guess = tm2.group(1).strip()
            else:
                # fallback: 2nd segment split by ". "
                segs = [s.strip() for s in body.split(". ") if len(s.strip()) > 10]
                title_guess = segs[1] if len(segs) > 1 else segs[0] if segs else ""

        entries.append({
            "key":          key,
            "raw":          body,
            "title_guess":  title_guess,
            "is_chinese":   is_chinese,
            "is_todo":      is_todo,
        })
    return entries

# â”€â”€ æ ¼å¼åŒ– API ç»“æœä¸ºæ ‡å‡† \bibitem â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def format_from_ss(key, paper):
    authors = paper.get("authors", [])
    auth_str = ", ".join(a["name"] for a in authors[:6])
    if len(authors) > 6:
        auth_str += ", et al."
    year    = paper.get("year", "n.d.")
    title   = paper.get("title", "")
    venue   = ""
    if paper.get("journal") and paper["journal"].get("name"):
        venue = paper["journal"]["name"]
    elif paper.get("venue"):
        venue = paper["venue"]
    doi = ""
    ext = paper.get("externalIds", {})
    if ext.get("DOI"):
        doi = f" DOI: {ext['DOI']}."
    return (
        f"\\bibitem{{{key}}} {auth_str}. ({year}). {title}."
        f" \\textit{{{venue}}}.{doi}"
    )

def format_from_cr(key, item):
    authors = item.get("author", [])
    auth_parts = []
    for a in authors[:6]:
        name = a.get("family", "") + (", " + a.get("given", "") if a.get("given") else "")
        auth_parts.append(name.strip(", "))
    auth_str = ", ".join(auth_parts)
    if len(authors) > 6:
        auth_str += ", et al."
    titles = item.get("title", [""])
    title = titles[0] if titles else ""
    pub = item.get("published", {}).get("date-parts", [[None]])[0]
    year = pub[0] if pub else "n.d."
    venue = ""
    ct = item.get("container-title", [])
    if ct:
        venue = ct[0]
    doi = item.get("DOI", "")
    doi_str = f" DOI: {doi}." if doi else ""
    return (
        f"\\bibitem{{{key}}} {auth_str}. ({year}). {title}."
        f" \\textit{{{venue}}}.{doi_str}"
    )

# â”€â”€ ä¸»æµç¨‹ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def main():
    print("=" * 60)
    print("  å‚è€ƒæ–‡çŒ®éªŒè¯è„šæœ¬")
    print("=" * 60)

    entries = parse_bib(BIB_FILE)
    print(f"\nè§£æåˆ° {len(entries)} æ¡æ¡ç›®\n")

    results = []   # list of result dicts
    verified_bibs = []  # final corrected bibitem lines

    for i, entry in enumerate(entries):
        key   = entry["key"]
        title = entry["title_guess"]
        print(f"[{i+1:02d}/{len(entries)}] {key}")
        print(f"        title_guess: {title[:70]}")

        r = {
            "key":        key,
            "original":   entry["raw"],
            "title_in":   title,
            "is_chinese": entry["is_chinese"],
            "is_todo":    entry["is_todo"],
            "status":     "SKIP",
            "score":      None,
            "api_title":  None,
            "api_source": None,
            "corrected":  None,
        }

        # â”€â”€ Skip TODO entries â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        if entry["is_todo"]:
            print("        â†’ SKIP (TODO)")
            r["status"] = "TODO"
            results.append(r)
            verified_bibs.append(f"\\bibitem{{{key}}} % TODO: æœªèƒ½è‡ªåŠ¨è·å–ï¼Œè¯·æ‰‹åŠ¨è¡¥å……\n")
            continue

        # â”€â”€ Skip Chinese entries (SS has limited coverage) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        if entry["is_chinese"]:
            print("        â†’ SKIP (ä¸­æ–‡ï¼Œäººå·¥æ ¸éªŒ)")
            r["status"] = "CHINESE_SKIP"
            results.append(r)
            verified_bibs.append(f"\\bibitem{{{key}}} {entry['raw']}\n")
            continue

        if not title or len(title) < 8:
            print("        â†’ SKIP (æ— æ³•æå–æ ‡é¢˜)")
            r["status"] = "NO_TITLE"
            results.append(r)
            verified_bibs.append(f"\\bibitem{{{key}}} {entry['raw']}\n")
            continue

        # â”€â”€ Try Semantic Scholar â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        time.sleep(1.5)  # polite delay
        candidates = semantic_scholar_search(title)
        api_source = "SemanticScholar"

        if not candidates:
            # Fallback: CrossRef
            print("        SS not found, trying CrossRef...")
            time.sleep(1.0)
            candidates_cr = crossref_search(title)
            if candidates_cr:
                # convert CrossRef format
                best, score = best_match(
                    [{"title": c.get("title", [""])[0], "_cr": c}
                     for c in candidates_cr],
                    title
                )
                api_source = "CrossRef"
                if best and score >= THRESHOLD_WARN:
                    cr_item = best["_cr"]
                    api_title = (cr_item.get("title") or [""])[0]
                    r["api_title"]  = api_title
                    r["api_source"] = api_source
                    r["score"]      = score
                    corrected = format_from_cr(key, cr_item)
                    r["corrected"]  = corrected
                    status = "PASS" if score >= THRESHOLD_PASS else "WARN"
                    r["status"] = status
                    print(f"        CrossRef â†’ {status} (score={score:.2f})")
                    print(f"        api_title: {api_title[:70]}")
                    bib_line = corrected if score >= THRESHOLD_PASS else entry["raw"]
                    verified_bibs.append(f"\\bibitem{{{key}}} {bib_line}\n")
                    results.append(r)
                    continue
            r["status"] = "NOT_FOUND"
            print("        â†’ NOT FOUND on SS or CrossRef")
            results.append(r)
            verified_bibs.append(f"\\bibitem{{{key}}} {entry['raw']}\n")
            continue

        best, score = best_match(candidates, title)
        if best is None:
            r["status"] = "NOT_FOUND"
            results.append(r)
            verified_bibs.append(f"\\bibitem{{{key}}} {entry['raw']}\n")
            continue

        api_title = best.get("title", "")
        r["api_title"]  = api_title
        r["api_source"] = api_source
        r["score"]      = score

        if score >= THRESHOLD_PASS:
            corrected = format_from_ss(key, best)
            r["corrected"] = corrected
            r["status"]    = "PASS"
            verified_bibs.append(f"\\bibitem{{{key}}} {corrected}\n")
        elif score >= THRESHOLD_WARN:
            corrected = format_from_ss(key, best)
            r["corrected"] = corrected
            r["status"]    = "WARN"
            verified_bibs.append(f"\\bibitem{{{key}}} {entry['raw']}\n")  # keep original
        else:
            r["status"] = "FAIL"
            verified_bibs.append(f"\\bibitem{{{key}}} {entry['raw']}\n")

        print(f"        â†’ {r['status']} (score={score:.2f})")
        print(f"        api_title: {api_title[:70]}")
        results.append(r)

    # â”€â”€ Write verified .bib â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    with open(OUT_BIB, "w", encoding="utf-8") as f:
        f.write("% ============================================================\n")
        f.write("% å‚è€ƒæ–‡çŒ®æ¡ç›® â€” å·²éªŒè¯ç‰ˆæœ¬\n")
        f.write("% ç”Ÿæˆæ—¶é—´: 2026-02-24\n")
        f.write("% ============================================================\n\n")
        for line in verified_bibs:
            f.write(line)
            f.write("\n")

    # â”€â”€ Write Markdown report â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    counts = {s: sum(1 for r in results if r["status"] == s)
              for s in ["PASS", "WARN", "FAIL", "NOT_FOUND", "TODO",
                        "CHINESE_SKIP", "NO_TITLE"]}

    with open(REPORT, "w", encoding="utf-8") as f:
        f.write("# å‚è€ƒæ–‡çŒ®éªŒè¯æŠ¥å‘Š\n\n")
        f.write(f"ç”Ÿæˆæ—¶é—´ï¼š2026-02-24  \n")
        f.write(f"æ¥æºæ–‡ä»¶ï¼š`references_generated.bib`  \n\n")

        f.write("## æ€»è§ˆ\n\n")
        f.write(f"| çŠ¶æ€ | æ•°é‡ | è¯´æ˜ |\n")
        f.write(f"|------|------|------|\n")
        f.write(f"| âœ… PASS     | {counts.get('PASS',0)} | ç›¸ä¼¼åº¦ â‰¥ 80%ï¼Œå·²ç”¨APIç»“æœæ›´æ–°æ ¼å¼ |\n")
        f.write(f"| âš ï¸ WARN     | {counts.get('WARN',0)} | ç›¸ä¼¼åº¦ 55%~80%ï¼Œä¿ç•™åŸæ ¼å¼ï¼Œå»ºè®®äººå·¥æ ¸éªŒ |\n")
        f.write(f"| âŒ FAIL     | {counts.get('FAIL',0)} | ç›¸ä¼¼åº¦ < 55%ï¼Œæœªè‡ªåŠ¨æ›¿æ¢ |\n")
        f.write(f"| ğŸ” NOT_FOUND| {counts.get('NOT_FOUND',0)} | API æœªè¿”å›ç»“æœ |\n")
        f.write(f"| ğŸ“ TODO     | {counts.get('TODO',0)} | åŸå§‹æ–‡ä»¶ä¸­æ ‡è®°ä¸ºå¾…è¡¥å…… |\n")
        f.write(f"| ğŸ‡¨ğŸ‡³ ä¸­æ–‡     | {counts.get('CHINESE_SKIP',0)} | ä¸­æ–‡è®ºæ–‡ï¼Œè·³è¿‡APIéªŒè¯ |\n")
        f.write(f"| â“ NO_TITLE | {counts.get('NO_TITLE',0)} | æ— æ³•æå–æ ‡é¢˜ |\n\n")

        f.write("---\n\n")
        f.write("## é€æ¡ç»“æœ\n\n")

        for r in results:
            status_icon = {
                "PASS": "âœ…", "WARN": "âš ï¸", "FAIL": "âŒ",
                "NOT_FOUND": "ğŸ”", "TODO": "ğŸ“",
                "CHINESE_SKIP": "ğŸ‡¨ğŸ‡³", "NO_TITLE": "â“",
            }.get(r["status"], "â“")

            f.write(f"### {status_icon} `{r['key']}`\n\n")
            f.write(f"**çŠ¶æ€ï¼š** {r['status']}")
            if r["score"] is not None:
                f.write(f"  ï¼ˆç›¸ä¼¼åº¦ï¼š{r['score']:.2%}ï¼Œæ¥æºï¼š{r['api_source']}ï¼‰")
            f.write("\n\n")

            f.write(f"**åŸå§‹æ¡ç›®ï¼š**\n```\n{r['original']}\n```\n\n")

            if r["api_title"]:
                f.write(f"**API è¿”å›æ ‡é¢˜ï¼š** {r['api_title']}\n\n")

            if r["corrected"] and r["status"] == "PASS":
                f.write(f"**å·²æ›´æ–°ä¸ºï¼š**\n```\n{r['corrected']}\n```\n\n")
            elif r["corrected"] and r["status"] == "WARN":
                f.write(f"**å»ºè®®æ ¼å¼ï¼ˆæœªè‡ªåŠ¨æ›¿æ¢ï¼‰ï¼š**\n```\n{r['corrected']}\n```\n\n")

            if r["status"] in ("FAIL", "NOT_FOUND"):
                f.write(f"> âš ï¸ å»ºè®®æ‰‹åŠ¨é€šè¿‡ Google Scholar æœç´¢æ ‡é¢˜éªŒè¯ã€‚\n\n")

            f.write("---\n\n")

    print("\n" + "=" * 60)
    print("  éªŒè¯å®Œæˆ")
    print("=" * 60)
    print(f"  âœ… PASS     : {counts.get('PASS',0)}")
    print(f"  âš ï¸  WARN     : {counts.get('WARN',0)}")
    print(f"  âŒ FAIL     : {counts.get('FAIL',0)}")
    print(f"  ğŸ” NOT_FOUND: {counts.get('NOT_FOUND',0)}")
    print(f"  ğŸ“ TODO     : {counts.get('TODO',0)}")
    print(f"  ğŸ‡¨ğŸ‡³ ä¸­æ–‡     : {counts.get('CHINESE_SKIP',0)}")
    print(f"\n  å·²å†™å…¥: {OUT_BIB}")
    print(f"  æŠ¥å‘Š  : {REPORT}")

if __name__ == "__main__":
    main()
