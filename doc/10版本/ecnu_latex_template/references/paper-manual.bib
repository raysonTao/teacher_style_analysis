% ============================================================
% 参考文献条目 — 整理版本
% 生成时间: 2026-02-27
% 共约 69 条，按主题分类
% 格式遵循 GB/T 7714—2005
% ============================================================

% ─── 一、教学风格理论与课堂量化分析 ──────────────────────

\bibitem{ref_anderson1939}{H. H. Anderson. (1939). The Measurement of Domination and of Socially Integrative Behavior in Teachers' Contacts with Children. \textit{Child Development}, 10(2). DOI: 10.1111/J.1467-8624.1939.TB04615.X.}

\bibitem{ref_intent}{N. Flanders. (1963). Intent, Action and Feedback: A Preparation for Teaching. \textit{Journal of Teacher Education}, 14(3). DOI: 10.1177/002248716301400305.}

\bibitem{ref_grasha1996}{Grasha, A. F. (1996). \textit{Teaching With Style: A Practical Guide to Enhancing Learning by Understanding Teaching and Learning Styles}. Pittsburgh: Alliance Publishers.}

\bibitem{ref_pianta2008}{Pianta, R. C., La Paro, K. M., \& Hamre, B. K. (2008). \textit{Classroom Assessment Scoring System (CLASS) Manual, K-3}. Baltimore: Paul H. Brookes Publishing.}

\bibitem{ref_gu2007itias}{顾小清, 王炜. 信息技术整合课堂的互动分析系统研究[J]. 中国电化教育, 2007(12): 48--53.}

\bibitem{ref_zhou2019}{Zhou, Suping, Jia, Jia, Yin, Yufeng, Li, Xiang, Yao, Yang, Zhang, Ying, et al. (2019). Understanding the Teaching Styles by an Attention Based Multi-task Cross-media Dimensional Modeling. \textit{Proceedings of the 27th ACM International Conference on Multimedia}. DOI: 10.1145/3343031.3351059.}

\bibitem{ref_guerrero}{J. D. Guerrero-Sosa, Francisco P. Romero, V. Menéndez-Domínguez, J. Serrano-Guerrero, Andrés Montoro-Montarroso, J. A. Olivas. (2025). A Comprehensive Review of Multimodal Analysis in Education. \textit{Applied Sciences}. DOI: 10.3390/app15115896.}

\bibitem{ref_yurum2025}{Ozan Raşít Yürüm. (2025). Technology-Enhanced Multimodal Learning Analytics in Higher Education: A Systematic Literature Review. \textit{IEEE Access}. DOI: 10.1109/ACCESS.2025.3572467.}

% ─── 二、教师画像与智能评价 ────────────────────────────────

\bibitem{ref_hu2019portrait}{胡小勇, 林祥耀. 精准教研视域下的教师画像研究[J]. 电化教育研究, 2019, 40(7): 21--27.}

\bibitem{ref_hu2024}{胡小勇, 眭慧, 陈莹, 穆肃. 多场景融合的教师数字画像：模式建构与应用方法[J]. 中国远程教育, 2024, 44(4).}

\bibitem{ref_hu2024b}{胡小勇, 孙硕, 穆肃. 基于画像技术的教师研修路径智能推荐研究[J]. 电化教育研究, 2024(2). DOI: 10.13811/j.cnki.eer.2024.02.015}

\bibitem{ref_chen2021}{陈鑫, 胡东芳. 教师画像的前沿探讨：定义、概念框架与研究边界[J]. 教师教育学报, 2021, 8(6): 1--8.}

\bibitem{ref_bai2024}{柏宏权, 朱俊. 小学人工智能教师画像构建研究[J]. 电化教育研究, 2024(7). DOI: 10.13811/j.cnki.eer.2024.07.013}

\bibitem{ref_k12}{黄荣怀, 陈庚, 张进宝, 陈桄, 汪燕. 面向K12教师的智能教育素养框架构建[J]. 开放教育研究, 2021, 27(4).}

\bibitem{ref_zhang2022}{张乐乐, 顾小清. 多模态数据支持的课堂教学行为分析模型与实践框架[J]. 开放教育研究, 2022, 28(6).}

\bibitem{ref_zhao2024}{Qiaoyue Zhao. (2024). Design of Teacher Portrait System Based on Knowledge Graph. \textit{2024 IEEE 2nd International Conference on Image Processing and Computer Applications (ICIPCA)}. DOI: 10.1109/ICIPCA61593.2024.10708989.}

\bibitem{ref_hu2024portrait}{Xiaoyong Hu, Hui Sui, Xingyu Geng, Li Zhao. (2024). Constructing a Teacher Portrait for the Artificial Intelligence Age Based on the Micro Ecological System Theory: A Systematic Review. \textit{Education and Information Technologies}. DOI: 10.1007/s10639-024-12513-5.}

\bibitem{ref_iseeyou}{Lee, Unggi, Jeong, Yeil, Koh, Junbo, Byun, Gyuri, Lee, Yunseo, Lee, Hyunwoong, et al. (2024). I See You: Teacher Analytics with GPT-4 Vision-Powered Observational Assessment. \textit{Smart Learning Environments}. DOI: 10.1186/s40561-024-00335-4.}

\bibitem{ref_borchers2023}{Conrad Borchers, Yeyu Wang, Shamya Karumbaiah, Muhammad Ashiq, D. Shaffer, Vincent Aleven. (2023). Revealing Networks: Understanding Effective Teacher Practices in AI-Supported Classrooms Using Transmodal Ordered Network Analysis. \textit{Proceedings of the 14th Learning Analytics and Knowledge Conference}. DOI: 10.1145/3636555.3636892.}

% ─── 三、课堂视频与行为识别 ────────────────────────────────

\bibitem{ref_simonyan2014twostream}{Simonyan, K., \& Zisserman, A. (2014). Two-Stream Convolutional Networks for Action Recognition in Videos. \textit{Advances in Neural Information Processing Systems (NeurIPS)}, 27.}

\bibitem{ref_tran2015c3d}{Tran, D., Bourdev, L., Fergus, R., Torresani, L., \& Paluri, M. (2015). Learning Spatiotemporal Features with 3D Convolutional Networks. \textit{Proceedings of the IEEE International Conference on Computer Vision (ICCV)}.}

\bibitem{ref_carreira2017i3d}{Carreira, J., \& Zisserman, A. (2017). Quo Vadis, Action Recognition? A New Model and the Kinetics Dataset. \textit{Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)}.}

\bibitem{ref_wang2016tsn}{Wang, L., Xiong, Y., Wang, Z., Qiao, Y., Lin, D., Tang, X., \& Van Gool, L. (2016). Temporal Segment Networks: Towards Good Practices for Deep Action Recognition. \textit{European Conference on Computer Vision (ECCV)}.}

\bibitem{ref_feichtenhofer2019slowfast}{Feichtenhofer, C., Fan, H., Malik, J., \& He, K. (2019). SlowFast Networks for Video Recognition. \textit{Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV)}.}

\bibitem{ref_dosovitskiy2021vit}{Dosovitskiy, A., Beyer, L., Kolesnikov, A., Weissenborn, D., Zhai, X., Unterthiner, T., Dehghani, M., Minderer, M., Heigold, G., Gelly, S., Uszkoreit, J., \& Houlsby, N. (2021). An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale. \textit{International Conference on Learning Representations (ICLR)}.}

\bibitem{ref_liu2022videoswin}{Liu, Z., Ning, J., Cao, Y., Wei, Y., Zhang, Z., Lin, S., \& Hu, H. (2022). Video Swin Transformer. \textit{Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)}.}

\bibitem{ref_yan2018}{Yan, S., Xiong, Y., \& Lin, D. (2018). Spatial Temporal Graph Convolutional Networks for Skeleton-Based Action Recognition. \textit{Proceedings of the AAAI Conference on Artificial Intelligence}, 32(1).}

\bibitem{ref_lugaresi2019}{Lugaresi, C., Tang, J., Nash, H., McClanahan, C., Uboweja, E., Hays, M., Zhang, F., Chang, C. L., Yong, M. G., Lee, J., Chang, W. T., Hua, W., Georg, M., \& Grundmann, M. (2019). MediaPipe: A Framework for Perceiving and Processing Reality. \textit{Third Workshop on Computer Vision for AR/VR at IEEE CVPR}.}

\bibitem{ref_yolov8}{Jocher, G., Chaurasia, A., \& Qiu, J. (2023). Ultralytics YOLOv8 (Version 8.0.0) [Computer software]. Zenodo. DOI: 10.5281/zenodo.7347926.}

\bibitem{ref_wojke2017}{N. Wojke, Alex Bewley, D. Paulus. (2017). Simple Online and Realtime Tracking with a Deep Association Metric. \textit{2017 IEEE International Conference on Image Processing (ICIP)}. DOI: 10.1109/ICIP.2017.8296962.}

\bibitem{ref_wu2024mctm}{Cong Wu, Xiaojun Wu, Tianyang Xu, Zhongwei Shen, J. Kittler. (2024). Motion Complement and Temporal Multifocusing for Skeleton-Based Action Recognition. \textit{IEEE Transactions on Circuits and Systems for Video Technology}. DOI: 10.1109/TCSVT.2023.3236430.}

\bibitem{ref_sitmlp2024}{Shaojie Zhang, Jianqin Yin, Yonghao Dang, Jiajun Fu. (2023). SiT-MLP: A Simple MLP With Point-Wise Topology Feature Learning for Skeleton-Based Action Recognition. \textit{IEEE Transactions on Circuits and Systems for Video Technology}. DOI: 10.1109/TCSVT.2024.3386553.}

\bibitem{ref_li2022}{Li, Yuanzhong, Deng, Zhengjie, Liu, Meijun, He, Shuqian, Wang, Yizhen, Jiang, Wenjuan. (2022). A Method for Analyzing Teacher Behavior in Classroom Based on the Long- and Short-Term Features of Pose Sequences. \textit{2022 9th International Conference on Digital Home (ICDH)}. DOI: 10.1109/icdh57206.2022.00043.}

\bibitem{ref_cai2025}{Cai, Ting, Xiong, Yu, He, Chengyang, Wu, Chao, Cai, Linqin. (2025). Classroom Teacher Behavior Analysis: The TBU Dataset and Performance Evaluation. \textit{Computer Vision and Image Understanding}. DOI: 10.1016/j.cviu.2025.104376.}

\bibitem{ref_classmind}{Qu, A., Wen, Y., \& Zhang, J. (2025). ClassMind: Scaling Classroom Observation and Instructional Feedback with Multimodal AI. \textit{arXiv:2509.18020}.}

\bibitem{ref_csbyolo}{Zhu, Wenqi, Yang, Zhijun. (2024). Csb-yolo: a Rapid and Efficient Real-time Algorithm for Classroom Student Behavior Detection. \textit{Journal of Real-Time Image Processing}. DOI: 10.1007/s11554-024-01515-8.}

\bibitem{ref_canovas2023}{Óscar Cánovas Reverte, Félix J. García Clemente, Federico Pardo. (2023). AI-driven Teacher Analytics: Informative Insights on Classroom Activities. \textit{2023 IEEE International Conference on Teaching, Assessment and Learning for Engineering (TALE)}. DOI: 10.1109/TALE56641.2023.10398309.}

\bibitem{ref_liu2023}{Ziyi Liu, Li Yang, Sannyuya Liu. (2023). A Teacher and Student Facial Expression Recognition Model Based on Classroom Teaching Videos. \textit{2023 International Conference on Intelligent Education and Intelligent Research (IEIR)}. DOI: 10.1109/IEIR59294.2023.10391209.}

\bibitem{ref_zhao2024review}{Zhao, Lanfei, Lin, Zixiang, Sun, Ruiyang, Wang, Aili. (2024). A Review of State-of-the-Art Methodologies and Applications in Action Recognition. \textit{Electronics}. DOI: 10.3390/electronics13234733.}

\bibitem{ref_shafizadegan2024}{Fatemeh Shafizadegan, A. Naghsh-Nilchi, Elham Shabaninia. (2024). Multimodal Vision-Based Human Action Recognition Using Deep Learning: A Review. \textit{Artificial Intelligence Review}. DOI: 10.1007/s10462-024-10730-5.}

\bibitem{ref_schiappa2023}{Schiappa, Madeline C., Rawat, Yogesh S., Shah, Mubarak. (2023). Self-Supervised Learning for Videos: A Survey. \textit{ACM Computing Surveys}. DOI: 10.1145/3577925.}

\bibitem{ref_saket2025}{Olfa Saket, A. B. Aicha, H. Fathallah. (2025). Deep Learning Applied for Abnormal Human Behavior Recognition in Video Surveillance Systems: A Systematic Review. \textit{Applied Intelligence}. DOI: 10.1007/s10489-025-06797-4.}

\bibitem{ref_actionformer}{Chen-Lin Zhang, Jianxin Wu, Yin Li. (2022). ActionFormer: Localizing Moments of Actions with Transformers. \textit{European Conference on Computer Vision (ECCV)}. DOI: 10.1007/978-3-031-19772-7\_29.}

\bibitem{ref_actionformer_ego4d}{Mu, F., Mo, S., Wang, G., \& Li, Y. (2022). Where a Strong Backbone Meets Strong Features -- ActionFormer for Ego4D Moment Queries Challenge. \textit{arXiv:2211.09074}.}

\bibitem{ref_tridet}{Ding Shi, Yujie Zhong, Qiong Cao, Lin Ma, Jia Li, Dacheng Tao. (2023). TriDet: Temporal Action Detection with Relative Boundary Modeling. \textit{2023 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)}. DOI: 10.1109/CVPR52729.2023.01808.}

\bibitem{ref_snag}{Fangzhou Mu, Sicheng Mo, Yin Li. (2024). SnAG: Scalable and Accurate Video Grounding. \textit{2024 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)}. DOI: 10.1109/CVPR52733.2024.01791.}

\bibitem{ref_rafique}{M. Rafique, Faheem Khaskheli, Malik Tahir Hassan, Sheraz Naseer, M. Jeon. (2022). Employing Automatic Content Recognition for Teaching Methodology Analysis in Classroom Videos. \textit{PLoS ONE}. DOI: 10.1371/journal.pone.0263448.}

\bibitem{ref_riordan2025}{J. Riordan, Lynn Revell, B. Bowie, Sabina Hulbert, M. Woolley, Caroline Thomas. (2024). Multimodal Classroom Interaction Analysis Using Video-Based Methods of the Pedagogical Tactic of (un)grouping. \textit{Pedagogies: An International Journal}. DOI: 10.1080/1554480X.2024.2313978.}

% ─── 四、语音与音频情感分析 ────────────────────────────────

\bibitem{ref_hannun2014deepspeech}{Hannun, A., Case, C., Casper, J., Catanzaro, B., Diamos, G., Elsen, E., Prenger, R., Satheesh, S., Sengupta, S., Coates, A., \& Ng, A. Y. (2014). Deep Speech: Scaling up End-to-end Speech Recognition. \textit{arXiv:1412.5567}.}

\bibitem{ref_radford2022whisper}{Radford, A., Kim, J. W., Xu, T., Brockman, G., McLeavey, C., \& Sutskever, I. (2023). Robust Speech Recognition via Large-Scale Weak Supervision. \textit{Proceedings of the 40th International Conference on Machine Learning (ICML)}.}

\bibitem{ref_baevski2020}{Baevski, A., Zhou, Y., Mohamed, A., \& Auli, M. (2020). Wav2vec 2.0: A Framework for Self-Supervised Learning of Speech Representations. \textit{Advances in Neural Information Processing Systems (NeurIPS)}, 33.}

\bibitem{ref_liang}{Liang Jie, Xiaoyan Zhao, Zhaohui Zhang. (2020). Speech Emotion Recognition of Teachers in Classroom Teaching. \textit{2020 Chinese Control And Decision Conference (CCDC)}. DOI: 10.1109/CCDC49329.2020.9164823.}

\bibitem{ref_donnelly}{Donnelly, P., Blanchard, N., Samei, B., Olney, A. M., Sun, X., Ward, B., Kelly, S., Nystrand, M., \& D'Mello, S. K. (2016). Automatic Teacher Modeling from Live Classroom Audio. \textit{Proceedings of the 2016 Conference on User Modeling, Adaptation and Personalization (UMAP)}.}

\bibitem{ref_pardo2025audio}{Federico Pardo, Óscar Cánovas, Félix J. García Clemente. (2025). Audio Features in Education: A Systematic Review of Computational Applications and Research Gaps. \textit{Applied Sciences}. DOI: 10.3390/app15126911.}

% ─── 五、文本语义与对话行为识别 ───────────────────────────

\bibitem{ref_mikolov2013word2vec}{Mikolov, T., Chen, K., Corrado, G., \& Dean, J. (2013). Efficient Estimation of Word Representations in Vector Space. \textit{arXiv:1301.3781}.}

\bibitem{ref_vaswani2017}{Vaswani, A., Shazeer, N., Parmar, N., Uszkoreit, J., Jones, L., Gomez, A. N., Kaiser, L., \& Polosukhin, I. (2017). Attention Is All You Need. \textit{Advances in Neural Information Processing Systems (NeurIPS)}, 30.}

\bibitem{ref_devlin2018}{Devlin, J., Chang, M. W., Lee, K., \& Toutanova, K. (2018). BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding. \textit{arXiv:1810.04805}.}

\bibitem{ref_zhang2021speech}{Zhang, Xilin, Wang, Jiaqi, Wan, Zhenhong, Luo, Zuying. (2021). Classification of Classroom Teachers' Speech Intention Based on Deep Learning. \textit{2021 International Conference on Computer Engineering and Application (ICCEA)}. DOI: 10.1109/iccea53728.2021.00053.}

\bibitem{ref_han}{Qing Han, L. Luo, Zhong Sun. (2020). Research on Teachers' Behavior in the Class Recognition on Based on Text Classification Technology. \textit{2020 IEEE 10th International Conference on Electronics Information and Emergency Communication (ICEIEC)}. DOI: 10.1109/ICEIEC49280.2020.9152304.}

\bibitem{ref_sapena}{Óscar Sapena, E. Onaindía. (2022). Multimodal Classification of Teaching Activities from University Lecture Recordings. \textit{Applied Sciences}, 12(9). DOI: 10.3390/app12094785.}

% ─── 六、多模态融合与时序建模 ────────────────────────────

\bibitem{ref_gu2023mamba}{Gu, A., \& Dao, T. (2023). Mamba: Linear-Time Sequence Modeling with Selective State Spaces. \textit{arXiv:2312.00752}.}

\bibitem{ref_vmrnn2024}{Tang, Y., Peng, P., Wen, Q., Zhou, T., Sun, L., \& Jin, R. (2024). VMRNN: Integrating State Space Models and LSTMs for Efficient and Effective Spatiotemporal Forecasting. \textit{arXiv:2405.16773}.}

\bibitem{ref_ye2024diff}{Ye, T., Dong, L., Xia, Y., Sun, Y., Zhu, Y., Huang, G., \& Wei, F. (2024). Differential Transformer. \textit{arXiv:2410.05258}.}

\bibitem{ref_ahmad2024}{Ahmad, Kashif, Qadir, Junaid, Al-Fuqaha, Ala, Iqbal, Waleed, El-Hassan, Ammar, Benhaddou, Driss, et al. (2020). Data-Driven Artificial Intelligence in Education: A Comprehensive Review. \textit{OSF Preprints}. DOI: 10.35542/osf.io/zvu2n.}

\bibitem{ref_howard}{S. Howard, Jie Yang, Jun Ma, C. Ritz, Jiahong Zhao, K. Wynne. (2018). Using Data Mining and Machine Learning Approaches to Observe Technology-Enhanced Learning. \textit{2018 IEEE International Conference on Teaching, Assessment, and Learning for Engineering (TALE)}. DOI: 10.1109/TALE.2018.8615443.}

% ─── 七、可解释性分析 ─────────────────────────────────────

\bibitem{ref_lundberg2017}{Lundberg, S. M., \& Lee, S. I. (2017). A Unified Approach to Interpreting Model Predictions. \textit{Advances in Neural Information Processing Systems (NeurIPS)}, 30.}

% ─── 八、其他辅助文献 ─────────────────────────────────────

\bibitem{ref_lecture2notes}{Housen, H. T. (2020). Lecture2Notes: Summarizing Lecture Videos by Classifying Slides and Analyzing Text. \textit{arXiv preprint}.}

\bibitem{ref_liu2022rfm}{Qifang Liu, Wuying Deng. (2022). Animation User Value Portrait Based on RFM Model under Big Data. \textit{Mathematical Problems in Engineering}. DOI: 10.1155/2022/8246540.}
