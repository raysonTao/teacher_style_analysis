
# 第三章 研究方法与总体设计


## 3.1 系统总体思路与研究框架

本研究以”基于课堂录像的教师风格画像分析系统”为核心目标，构建一个集多模态特征提取、风格映射建模、画像生成与可视化反馈 于一体的分析体系。研究总体思路遵循”数据采集—特征建模—风格映射—结果反馈”的主线，旨在实现从课堂视频到教学风格画像的全流程量化分析与智能反馈。


### 3.1.1总体研究思路

在教育信息化与人工智能技术的背景下，教师课堂行为与教学风格的客观识别与分析是推动教学质量评价科学化的重要方向。传统的教师评价多依赖主观观察和问卷调查，难以反映教学过程中的动态变化与多维特征。本研究借助多模态学习分析（MMLA）框架，综合运用计算机视觉、语音识别与自然语言处理等技术，对教师在课堂中的非言语行为与语言特征进行量化建模，从而构建教师风格画像，实现教学风格的客观、可解释识别。

系统由四个层次构成：

（1）数据采集与预处理层：通过录播系统采集课堂视频与音频数据，并利用语音分离、视频抽帧、语音转写等方法完成多模态数据清洗与时序同步。该阶段旨在为后续特征提取与融合提供统一的时间基准与数据格式。

研究的总体流程如图3-1所示（可在论文排版时绘制对应流程图）。

（2）多模态特征提取层：五模块创新架构

本研究针对现有技术局限，设计了五模块创新架构：

音频模态：采用Wav2Vec2自监督学习模型提取深层声学表征，解决传统MFCC特征无法捕捉复杂情感语境的问题；配合情感嵌入网络获取15维音频特征向量（包含声学嵌入、情绪极性、韵律特征等）。

文本模态：引入基于BERT的对话行为识别（Dialogue Act Recognition），将教师话语从内容分析提升至”提问”“指令”“解释”等教学意图识别，生成25维语义特征向量（包含意图标签、关键词密度、逻辑连接词等）。

视频模态：采用YOLOv8检测 + DeepSORT多目标跟踪 + MediaPipe姿态估计 + ST-GCN时空图卷积的完整pipeline，实现多人场景下的稳定教师追踪与动态行为识别，输出20维视频特征向量（包含动作类别、时长、空间分布等）。

规则特征：基于教育学理论提取7维规则特征（互动水平、逻辑清晰度、情感投入等），作为深度特征的���解释性补充。

MMAN融合模型：采用跨模态注意力网络（Multi-Modal Attention Network），通过Transformer捕获模态间依赖 + BiLSTM建模时序关系 + AttentionPooling聚合特征，自适应地融合多模态信息并输出风格分类结果。
