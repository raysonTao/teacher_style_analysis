## 3.4 实验设置

### 3.4.1 数据集划分

本研究使用自建的教师风格数据集（209个样本，7类风格），样本分布见表3.1。

**数据集划分策略**：

为保证模型评估的可靠性，采用分层随机抽样（Stratified Random Sampling）进行数据集划分，确保训练集、验证集、测试集中各风格类别的比例与总体数据集一致。

- **训练集**：$D_{\text{train}} = 125$样本（60%）
- **验证集**：$D_{\text{val}} = 31$样本（15%）
- **测试集**：$D_{\text{test}} = 53$样本（25%）

**表3.3：数据集各风格类别分布**

| 风格类别 | 总样本数 | 训练集 | 验证集 | 测试集 |
|---------|---------|-------|--------|--------|
| 理论讲授型 | 28 | 17 | 4 | 7 |
| 耐心细致型 | 32 | 19 | 5 | 8 |
| 启发引导型 | 35 | 21 | 5 | 9 |
| 题目驱动型 | 26 | 16 | 4 | 6 |
| 互动导向型 | 31 | 19 | 5 | 7 |
| 逻辑推导型 | 29 | 17 | 4 | 8 |
| 情感表达型 | 28 | 16 | 4 | 8 |
| **总计** | **209** | **125** | **31** | **53** |

**类别平衡性处理**：

由于各类别样本数量存在差异（26-35），训练时采用**加权交叉熵损失**处理类别不平衡：

$$\mathcal{L}_{\text{weighted}} = - \sum_{i = 1}^{N}{\sum_{k = 1}^{7}w_{k}} \cdot y_{i,k}\log\left( {\widehat{y}}_{i,k} \right)$$

其中，类别权重 $w_{k}$ 与样本数成反比：

$$w_{k} = \frac{N}{7 \cdot n_{k}}$$

$n_{k}$ 是类别 $k$ 的样本数，$N$ 是总样本数。

**具体权重**：

| 风格类别 | 样本数 | 权重 $w_k$ |
|---------|-------|-----------|
| 理论讲授型 | 28 | 1.07 |
| 耐心细致型 | 32 | 0.93 |
| 启发引导型 | 35 | 0.85 |
| 题目驱动型 | 26 | 1.14 |
| 互动导向型 | 31 | 0.96 |
| 逻辑推导型 | 29 | 1.03 |
| 情感表达型 | 28 | 1.07 |

### 3.4.2 实验环境配置

#### （1）硬件环境

**表3.4：硬件配置**

| 硬件类型 | 型号/规格 | 说明 |
|---------|---------|------|
| GPU | NVIDIA RTX 3090（24GB） | 主要用于模型训练与推理 |
| CPU | Intel Xeon Gold 6248R（3.0GHz, 48核） | 用于数据预处理 |
| 内存 | 256GB DDR4 | 支持大批量数据加载 |
| 存储 | 2TB NVMe SSD | 高速读写视频数据 |

#### （2）软件环境

**表3.5：软件配置**

| 软件类型 | 版本 | 说明 |
|---------|------|------|
| 操作系统 | Ubuntu 20.04 LTS | 服务器操作系统 |
| Python | 3.9.16 | 编程语言 |
| PyTorch | 2.0.1 | 深度学习框架 |
| CUDA | 11.8 | GPU加速 |
| cuDNN | 8.7.0 | 深度神经网络加速库 |
| Transformers | 4.28.1 | BERT等预训练模型 |
| OpenCV | 4.7.0 | 视频处理 |
| MediaPipe | 0.10.0 | 姿态估计 |
| Whisper | Large-v3 | 语音识别 |

#### （3）训练超参数

**表3.6：模型训练超参数**

| 超参数 | 值 | 说明 |
|-------|-----|------|
| 优化器 | Adam | 自适应学习率优化器 |
| 初始学习率 | $\eta_0 = 10^{-4}$ | - |
| 学习率调度 | Cosine Annealing | 余弦退火，$T_{\max}=50$ |
| 批大小（Batch Size） | 32 | 受GPU显存限制 |
| 训练轮数（Epochs） | 50 | 在验证集上早停（patience=10） |
| 权重衰减（Weight Decay） | $10^{-5}$ | L2正则化 |
| Dropout | 0.3 | 防止过拟合 |
| 标签平滑（Label Smoothing） | $\epsilon = 0.1$ | 提升泛化能力 |
| 梯度裁剪（Gradient Clipping） | max_norm=1.0 | 防止梯度爆炸 |

**学习率调度公式**（Cosine Annealing）：

$$\eta_t = \eta_{\min} + \frac{1}{2}(\eta_{\max} - \eta_{\min})\left(1 + \cos\left(\frac{T_{\text{cur}}}{T_{\max}}\pi\right)\right)$$

其中：
- $\eta_{\max} = 10^{-4}$ 是初始学习率
- $\eta_{\min} = 10^{-6}$ 是最小学习率
- $T_{\text{cur}}$ 是当前epoch
- $T_{\max} = 50$ 是总epoch数

**损失函数**：

结合加权交叉熵和标签平滑：

$$\mathcal{L}_{\text{total}} = \mathcal{L}_{\text{weighted-CE}} + \lambda \cdot \mathcal{L}_{\text{L2}}$$

其中：
- $\mathcal{L}_{\text{weighted-CE}}$ 是加权交叉熵损失（带标签平滑）
- $\mathcal{L}_{\text{L2}} = \|\mathbf{W}\|_2^2$ 是L2正则化项
- $\lambda = 10^{-5}$ 是正则化系数

**早停策略**（Early Stopping）：

监控验证集准确率，当连续10个epoch验证集准确率不提升时，停止训练并恢复最佳模型权重。

### 3.4.3 评估指标体系

#### （1）分类性能指标

**准确率（Accuracy）**：

$$\text{Accuracy} = \frac{1}{N}\sum_{i = 1}^{N}\mathbb{1}\left( {\widehat{y}}_{i} = y_{i} \right)$$

其中，$\mathbb{1}( \cdot )$ 是指示函数，${\widehat{y}}_{i}$ 是预测标签，$y_{i}$ 是真实标签。

**精确率（Precision）与召回率（Recall）**：

对于类别 $k$：

$$\text{Precision}_{k} = \frac{\text{TP}_{k}}{\text{TP}_{k} + \text{FP}_{k}}$$

$$\text{Recall}_{k} = \frac{\text{TP}_{k}}{\text{TP}_{k} + \text{FN}_{k}}$$

其中，$\text{TP}_{k}$ 是真正例，$\text{FP}_{k}$ 是假正例，$\text{FN}_{k}$ 是假负例。

**F1分数（F1-Score）**：

$$F1_{k} = 2 \times \frac{\text{Precision}_{k} \times \text{Recall}_{k}}{\text{Precision}_{k} + \text{Recall}_{k}}$$

**宏平均F1（Macro-F1）**：

$$\text{Macro-F1} = \frac{1}{K}\sum_{k = 1}^{K}F1_{k}$$

其中，$K = 7$ 是类别数。

**Cohen's Kappa系数**：

衡量模型预测与真实标签的一致性，排除随机猜测的影响：

$$\kappa = \frac{p_{o} - p_{e}}{1 - p_{e}}$$

其中：
- $p_{o}$ 是观测一致性（Accuracy）
- $p_{e} = \sum_{k = 1}^{K}\frac{n_{k,\text{true}} \cdot n_{k,\text{pred}}}{N^{2}}$ 是期望一致性

**Kappa值解释**：
- $\kappa < 0.4$：一致性差
- $0.4 \leq \kappa < 0.75$：中等一致性
- $\kappa \geq 0.75$：实质性一致

#### （2）统计显著性检验

**配对t检验（Paired t-test）**：

用于比较两个模型在相同测试集上的性能差异。设模型A和模型B在 $n$ 个样本上的准确率差异为 $d_{i} = A_{i} - B_{i}$，则：

$$t = \frac{\bar{d}}{s_{d}/\sqrt{n}}$$

其中：
- $\bar{d} = \frac{1}{n}\sum_{i = 1}^{n}d_{i}$ 是均值差异
- $s_{d} = \sqrt{\frac{1}{n - 1}\sum_{i = 1}^{n}\left( d_{i} - \bar{d} \right)^{2}}$ 是标准差

在显著性水平 $\alpha = 0.05$ 下，当 $|t| > t_{\alpha/2,n - 1}$ 时，拒绝原假设（两模型无差异）。

**McNemar检验**：

用于消融实验，检验模块移除对性能的影响。构建2×2列联表：

|  | 完整模型正确 | 完整模型错误 |
|--|-------------|-------------|
| **简化模型正确** | $n_{11}$ | $n_{12}$ |
| **简化模型错误** | $n_{21}$ | $n_{22}$ |

卡方统计量：

$$\chi^{2} = \frac{\left( n_{12} - n_{21} \right)^{2}}{n_{12} + n_{21}}$$

当 $\chi^{2} > \chi_{0.05,1}^{2} = 3.84$ 时，认为模块移除的影响显著。

**Cohen's d效应量**：

衡量两个模型性能差异的实际意义：

$$d = \frac{\bar{x}_1 - \bar{x}_2}{s_{\text{pooled}}}$$

其中，$s_{\text{pooled}} = \sqrt{\frac{(n_1-1)s_1^2 + (n_2-1)s_2^2}{n_1+n_2-2}}$ 是合并标准差。

**效应量解释**：
- $|d| < 0.2$：小效应
- $0.2 \leq |d| < 0.5$：中等效应
- $|d| \geq 0.5$：大效应

#### （3）其他评估指标

**混淆矩阵（Confusion Matrix）**：

展示各类别的预测结果分布，帮助分析模型的错误模式。

**ROC曲线与AUC**：

对于多分类问题，采用One-vs-Rest策略计算每个类别的ROC曲线和AUC（Area Under Curve），然后取宏平均：

$$\text{Macro-AUC} = \frac{1}{K}\sum_{k=1}^{K}\text{AUC}_k$$

**处理速度**：

- **特征提取速度**：秒/片段（Pipeline并行）
- **模型推理速度**：秒/样本（批大小=32）
- **端到端处理速度**：分钟/45分钟课堂

### 3.4.4 实验对比基线

为全面评估本研究提出的SHAPE模型的有效性，设计了以下对比基线：

#### （1）单模态基线

- **Video-Only**：仅使用20维视频特征
- **Audio-Only**：仅使用15维音频特征
- **Text-Only**：仅使用35维文本特征

#### （2）简单融合基线

- **Early Fusion**：直接拼接三模态特征（70维），输入到MLP分类器
- **Late Fusion**：分别训练三个单模态分类器，结果加权平均（固定权重 $w_v=0.4, w_a=0.3, w_t=0.3$）

#### （3）消融实验基线

- **SHAPE w/o Attention**：移除跨模态注意力，使用简单拼接
- **SHAPE w/o BiLSTM**：移除时序建模模块
- **SHAPE w/o H-DAR**：将文本特征从35维（含H-DAR）简化为25维（仅统计特征）

所有基线模型使用相同的训练超参数和数据集划分，确保对比的公平性。

### 3.4.5 可重复性保障

为保证实验的可重复性，采取以下措施：

1. **随机种子固定**：设置PyTorch、NumPy、Python的随机种子为42
   ```python
   torch.manual_seed(42)
   np.random.seed(42)
   random.seed(42)
   ```

2. **确定性算法**：启用PyTorch的确定性模式
   ```python
   torch.backends.cudnn.deterministic = True
   torch.backends.cudnn.benchmark = False
   ```

3. **数据集划分固定**：使用固定的随机种子进行数据集划分，并保存划分结果

4. **代码开源**：实验代码、预训练模型、数据集划分文件将在论文发表后开源

5. **实验记录**：使用TensorBoard记录训练过程中的损失、准确率曲线

**表3.7：实验可重复性清单**

| 项目 | 措施 | 状态 |
|-----|------|------|
| 随机种子 | 固定为42 | ✓ |
| 确定性模式 | PyTorch确定性算法 | ✓ |
| 数据集划分 | 固定划分文件 | ✓ |
| 超参数记录 | 详细记录所有超参数 | ✓ |
| 代码管理 | Git版本控制 | ✓ |
| 实验日志 | TensorBoard可视化 | ✓ |
| 环境配置 | requirements.txt | ✓ |
