\chapter*{\xiaosan\heiti{摘\quad 要}}
\addcontentsline{toc}{chapter}{摘要}

在教育数字化转型的浪潮中，海量课堂录像数据亟待被有效利用以赋能教学。教师教学风格是影响课堂质量的关键因素，但传统评价方法主观性强、反馈滞后、覆盖面窄，难以满足智慧教育环境下对客观、实时、可量化课堂反馈的需求。为此，本研究设计并实现了一个基于多模态深度学习的教师教学风格画像分析系统，旨在提供客观、精细、可解释的智能评价新范式。

现有课堂分析技术：(1)单模态视频或音频难以全面刻画教学风格；(2)简单融合策略效果有限——特征拼接或结果加权忽略了模态间的交互关系；(3)风格识别结果缺乏可解释性——难以理解模型决策依据和特征贡献度。

针对上述挑战，本研究提出了\textbf{SHAPE (Semantic Hierarchical Attention Profiling Engine，语义层次化注意力画像引擎)}，通过语义驱动分段、层次化教学意图识别和跨模态注意力机制实现特征的自适应融合与风格的精准画像。具体创新包括：

\begin{enumerate}
    \item \textbf{数据分段策略优化}：提出语义驱动的话语分段策略，通过依存句法分析和话语边界检测，保持教学话语的语义完整性（完整率从76.6\%提升至95.3\%），使教学意图识别F1值提升\textbf{5.2\%}，风格识别准确率提升\textbf{2.1\%}；

    \item \textbf{音频模态}：不仅将音频用于语音情绪识别，在课堂场景下进行微调，使用自动语音识别（ASR，语音转文字）技术将音频转化为文本模态，为意图识别打下基础。

    \item \textbf{文本模态}：引入基于BERT的层次化细粒度对话行为识别（Hierarchical Dialogue Act Recognition），采用两层分类架构（粗分类4类+细分类10类），将传统的4类粗糙分类扩展为10类细粒度分类（包括启发性提问、逻辑推导、概念定义、案例分析等），更有效地捕捉不同教学风格的特征性语言模式，F1值比关键词规则方法提升\textbf{0.19}；

    \item \textbf{视觉模态}：使用ReID算法实现稳定的教师身份追踪，并采用时空图卷积网络对骨骼序列进行时序建模，相比单帧规则识别准确率提升\textbf{17.7个百分点}；

    \item \textbf{智能融合与解释}：设计的SHAPE通过跨模态注意力机制自适应地融合视觉、音频、文本特征，并结合注意力权重与SHAP可解释性分析，提升模型决策依据的可追溯性。
\end{enumerate}

在自建的教师风格数据集（209个样本，7类风格）上，SHAPE在风格识别任务中取得了\textbf{93.5\%}的准确率，显著优于单一模态方法（最佳单模态78.3\%，提升\textbf{15.2个百分点}）和简单融合方法（特征拼接85.2\%，提升\textbf{8.3个百分点}；结果加权87.6\%，提升\textbf{5.9个百分点}）。消融实验进一步证实，语义驱动分段策略使风格识别准确率提升\textbf{2.1个百分点}，跨模态注意力模块的移除导致性能下降\textbf{2.7个百分点}（$p < 0.01$），验证了这些改进的有效性。

\textbf{【模态重要性分析】}可解释性分析揭示了不同教学风格对各模态的依赖模式存在显著差异：情感表达型教师最依赖音频特征（权重\textbf{0.62}），互动导向型最依赖视觉特征（权重\textbf{0.50}），逻辑推导型最依赖文本特征（权重\textbf{0.53}）。这些发现揭示了不同风格的多模态特征依赖模式。

本系统能够生成直观、可追溯的教师风格画像（风格雷达图、模态贡献度分析、典型片段回放），为教师风格认知和教学研究提供了科学、客观、精细化的数据支撑。

\vspace{0.5cm}
\sihao{\heiti{关键词：}}\xiaosi{教师教学风格；多模态学习分析；跨模态注意力；深度学习；可解释人工智能}
