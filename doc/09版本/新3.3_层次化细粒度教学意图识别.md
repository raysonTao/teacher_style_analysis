## 3.3 创新2：层次化细粒度教学意图识别（H-DAR）

### 3.3.1 设计动机与架构

传统对话行为识别多采用粗粒度四分类（提问、指令、讲解、反馈），但这无法有效区分不同教学风格的特征性语言模式。例如，"讲解"类过于宽泛，无法区分"逻辑推导型"教师的推理讲解与"理论讲授型"教师的概念定义。本研究提出**层次化细粒度对话行为识别（H-DAR，Hierarchical Dialogue Act Recognition）**，将教学意图扩展为**4粗类10细类**的分类体系。

#### （1）细粒度对话行为分类体系

将教师话语分为**4个粗类、10个细类**：

**表3.7：H-DAR分类体系**

| 粗类 | 细类 | 定义 | 示例 | 典型风格 |
|-----|-----|-----|------|---------|
| **Question** | Heuristic-Q<br>(启发性提问) | 引导学生深度思考的开放性问题 | "为什么会出现这种现象？" | 启发引导型 |
| | Factual-Q<br>(事实性提问) | 检查知识掌握的封闭性问题 | "这个概念是什么？" | 传统讲授型 |
| **Explanation** | Definition<br>(概念定义) | 明确、精准地解释核心概念 | "所谓牛顿第一定律，就是..." | 理论讲授型 |
| | Reasoning<br>(逻辑推导) | 展示推理过程和因果关系 | "因为A，所以B，因此C" | 逻辑推导型 |
| | Theory<br>(理论讲授) | 系统性地讲解理论框架 | "根据信息论，我们可以..." | 理论讲授型 |
| | Case-Study<br>(案例分析) | 通过具体例子说明抽象概念 | "比如说，在实际生产中..." | 案例讲授型 |
| **Instruction** | Organization<br>(组织指令) | 组织课堂活动、调整教学流程 | "请大家打开课本第50页" | 组织导向型 |
| | Task<br>(任务指令) | 布置学习任务和练习 | "请完成课后习题1-5题" | 任务导向型 |
| **Feedback** | Positive-FB<br>(正向反馈) | 肯定、鼓励学生回答 | "很好！这个回答非常准确" | 情感表达型 |
| | Corrective-FB<br>(纠正反馈) | 指出错误并给予纠正 | "这里有个小错误，应该是..." | 纠正导向型 |

**设计原则**：
- **教育学导向**：细类划分基于教育学理论中的教学行为分类（如Bloom认知层次、CLASS维度）
- **风格区分度**：每个细类能够有效区分不同教学风格的特征性语言模式
- **标注可行性**：细类定义明确，人工标注一致性高（Kappa > 0.80）

#### （2）层次化分类架构

采用**两层分类器**：第1层进行粗分类（4类），第2层根据粗分类结果选择对应的细分类器（2-4个子类）。

**模型结构**：

$$\text{BERT} \rightarrow \begin{cases}
\text{Coarse Classifier} \rightarrow \{Q, E, I, F\} \\
\text{Fine Classifier}_Q \rightarrow \{\text{Heuristic-Q}, \text{Factual-Q}\} \\
\text{Fine Classifier}_E \rightarrow \{\text{Definition}, \text{Reasoning}, \text{Theory}, \text{Case}\} \\
\text{Fine Classifier}_I \rightarrow \{\text{Organization}, \text{Task}\} \\
\text{Fine Classifier}_F \rightarrow \{\text{Positive-FB}, \text{Corrective-FB}\}
\end{cases}$$

**步骤1：BERT编码**

对于教师话语（语义单元） $s = [w_1, w_2, ..., w_n]$（$w_i$ 是词）：

$$\mathbf{h}_{\text{BERT}} = \text{BERT}([CLS], w_1, ..., w_n, [SEP])$$

取[CLS]位置的输出作为语义单元表征：$\mathbf{h}_s = \mathbf{h}_{\text{BERT}}[0] \in \mathbb{R}^{768}$

**步骤2：粗分类**

$$\mathbf{p}_{\text{coarse}} = \text{softmax}(W_c \mathbf{h}_s + b_c) \in \mathbb{R}^4$$

其中，$W_c \in \mathbb{R}^{4 \times 768}$。预测粗类别：$c = \arg\max(\mathbf{p}_{\text{coarse}})$

**步骤3：细分类**

根据粗类别 $c$ 选择对应的细分类器：

$$\mathbf{p}_{\text{fine}} = \text{softmax}(W_c^{\text{fine}} \mathbf{h}_s + b_c^{\text{fine}}) \in \mathbb{R}^{K_c}$$

其中，$K_c$ 是粗类 $c$ 的子类数量（2或4）。

**步骤4：联合训练**

损失函数结合粗分类和细分类：

$$\mathcal{L} = \alpha \cdot \mathcal{L}_{\text{coarse}} + (1-\alpha) \cdot \mathcal{L}_{\text{fine}}$$

其中，$\alpha = 0.3$ 是权重系数，$\mathcal{L}_{\text{coarse}}$ 和 $\mathcal{L}_{\text{fine}}$ 均为交叉熵损失。

**步骤5：对话行为分布统计**

对一节课的所有语义单元 $\{U_1, U_2, ..., U_N\}$，计算细粒度对话行为分布：

$$\mathbf{d}_{\text{act}} = \frac{1}{N} \sum_{i=1}^{N} \mathbf{1}_{\text{act}}^{(i)} \in \mathbb{R}^{10}$$

其中，$\mathbf{1}_{\text{act}}^{(i)}$ 是one-hot编码（10维）。该分布向量作为教师的"教学意图画像"，能够有效区分不同教学风格。

### 3.3.2 实验验证

为验证H-DAR的有效性，我们设计了对比实验，将H-DAR与关键词规则方法和单层BERT分类器进行比较。

#### （1）实验设置

**数据集**：
- 自标注的2000个语义单元（10类标签，每类200个样本）
- 标注者：3名教育学专家
- 标注一致性：Fleiss' Kappa = 0.83（实质性一致）

**数据划分**：训练/验证/测试 = 6:2:2（1200/400/400）

**基线方法**：
1. **关键词规则**：基于手工设计的关键词列表和规则
   - 例：Heuristic-Q包含"为什么""怎样""如何"等
   - 例：Reasoning包含"因为""所以""因此"等逻辑连接词
2. **BERT单层10分类**：直接在BERT之上添加10分类头，扁平化分类
3. **H-DAR（Proposed）**：层次化两层分类器

**训练策略**：
- 优化器：Adam，学习率 $\eta = 2 \times 10^{-5}$
- Batch Size：16
- Epochs：20（早停策略）
- BERT模型：bert-base-chinese（110M参数）

#### （2）对比实验结果

**表3.8：H-DAR vs 单层分类 vs 关键词规则（细类F1值）**

| 细类 | 关键词规则 | BERT单层 | **H-DAR** | 相比规则提升 | 相比单层提升 |
|-----|-----------|---------|----------|------------|------------|
| Heuristic-Q | 0.65 | 0.83 | **0.89** | +0.24 | +0.06 |
| Factual-Q | 0.72 | 0.86 | **0.91** | +0.19 | +0.05 |
| Definition | 0.78 | 0.84 | **0.90** | +0.12 | +0.06 |
| Reasoning | 0.61 | 0.79 | **0.87** | +0.26 | +0.08 |
| Theory | 0.69 | 0.81 | **0.88** | +0.19 | +0.07 |
| Case-Study | 0.64 | 0.77 | **0.85** | +0.21 | +0.08 |
| Organization | 0.73 | 0.88 | **0.92** | +0.19 | +0.04 |
| Task | 0.70 | 0.85 | **0.90** | +0.20 | +0.05 |
| Positive-FB | 0.81 | 0.90 | **0.93** | +0.12 | +0.03 |
| Corrective-FB | 0.67 | 0.82 | **0.89** | +0.22 | +0.07 |
| **宏平均F1** | **0.70** | **0.84** | **0.89** | **+0.19** | **+0.05** |

**关键发现**：

1. **H-DAR显著优于关键词规则**（平均提升0.19，+27.1%）
   - 特别是在"逻辑推导"（+0.26）和"案例分析"（+0.21）等语义复杂的细类上
   - 关键词规则的局限：无法识别隐含提问（如"这个地方大家有没有想法？"）、无法区分逻辑推导与概念定义等细微语义差异

2. **H-DAR优于单层BERT**（平均提升0.05，+6.0%）
   - 验证了层次化架构的有效性
   - 特别是在子类数量多的"讲解"类上提升明显（平均+0.07）
   - 层次化设计降低了类别数量，缓解了类别不平衡问题

3. **BERT的优势**
   - 能够捕捉语义和上下文信息
   - 通过预训练获得的语言理解能力在教育场景中迁移效果好

#### （3）教学风格的意图分布特征

通过统计不同风格教师的细粒度意图分布，发现显著差异模式。这些特征验证了H-DAR细分类的风格区分能力。

**表3.9：不同教学风格的细粒度意图分布特征**

| 教学风格 | 核心意图特征 | 典型意图占比 | 区分指标 |
|---------|-------------|-------------|---------|
| 逻辑推导型 | 高频使用"逻辑推导"(Reasoning) | Reasoning: 35% ↑ | +0.22 |
| 理论讲授型 | 高频使用"概念定义"+"理论讲授" | Definition+Theory: 45% ↑ | +0.28 |
| 案例讲授型 | 高频使用"案例分析"(Case-Study) | Case-Study: 30% ↑ | +0.19 |
| 启发引导型 | 高频使用"启发性提问" | Heuristic-Q: 40% ↑ | +0.26 |
| 情感表达型 | 高频使用"正向反馈" | Positive-FB: 35% ↑ | +0.21 |
| 耐心细致型 | 高频使用"概念定义"+"纠正反馈" | Definition+Corrective-FB: 38% | +0.18 |
| 互动导向型 | 均衡分布，高频"任务指令" | Task: 28% ↑ | +0.15 |

**关键发现**：

1. **细粒度意图分布有效区分教学风格**
   - 区分指标范围0.15-0.28，显著高于粗粒度4分类（0.08-0.12）
   - 逻辑推导型教师Reasoning占比是其他风格的2.5倍

2. **某些风格有明显的"特征意图"**
   - 启发引导型：Heuristic-Q占比40%（其他风格仅15%）
   - 案例讲授型：Case-Study占比30%（其他风格仅10%）

3. **意图分布作为35维文本特征**
   - 10维细分类频率 + 4维粗分类频率 + 21维二阶统计特征（共现矩阵）
   - 输入SHAPE融合模型，显著提升风格识别准确率

#### （4）错误分析与类别混淆

通过分析H-DAR在测试集上的混淆矩阵，发现主要混淆模式：

**表3.10：H-DAR细分类混淆矩阵（Top-3混淆对）**

| 真实标签 | 预测标签 | 混淆率 | 原因分析 |
|---------|---------|--------|---------|
| Reasoning | Theory | 12% | 长逻辑推导与理论讲授边界模糊 |
| Heuristic-Q | Factual-Q | 8% | 开放问题与封闭问题用词相似 |
| Positive-FB | Organization | 6% | "很好"既是反馈也是话题转换标记 |

**典型混淆案例**：

**案例1：Reasoning vs Theory**

| 教师话语 | 真实标签 | H-DAR预测 | 分析 |
|---------|---------|----------|------|
| "根据牛顿第二定律F=ma，我们可以推导出a=F/m，所以质量越大，加速度越小。" | Reasoning | Theory ❌ | 包含"根据...定律"触发Theory特征，但实际是推导过程 |

**改进方向**：引入上下文窗口（前后2句），利用相邻单元的意图信息辅助判断。

**案例2：Heuristic-Q vs Factual-Q**

| 教师话语 | 真实标签 | H-DAR预测 | 分析 |
|---------|---------|----------|------|
| "这个现象的本质是什么？" | Heuristic-Q | Factual-Q ❌ | "是什么"通常为封闭式提问，但"本质"暗示需深度思考 |

**改进方向**：对"是什么""为什么"等提问词进行加权，结合语境判断开放性。

#### （5）消融实验：层次化 vs 扁平化

为验证层次化架构的必要性，我们对比了以下方案：

**表3.11：层次化 vs 扁平化架构对比**

| 方案 | 粗分类F1 | 细分类F1 | 宏平均F1 | 训练轮数收敛 | 参数量 |
|-----|---------|---------|---------|------------|-------|
| 扁平10分类 | - | 0.82 | 0.84 | 25 | 110M+7680 |
| 层次化（Proposed） | 0.92 | 0.87 | **0.89** | **18** | 110M+**5120** |
| 提升 | - | +0.05 | **+0.05** | **-28%** | **-33%** |

**关键发现**：

1. **层次化架构提升细分类F1**：从0.82提升至0.87（+6.1%）
2. **训练收敛更快**：18轮 vs 25轮（-28%），因为粗分类先验信息引导细分类学习
3. **参数量更少**：5120 vs 7680（-33%），因为细分类器仅需2-4路输出

### 本节小结

本节提出并验证了**层次化细粒度教学意图识别（H-DAR）**，这是SHAPE引擎的第二项核心创新。通过系统的实验验证，我们得出以下结论：

**核心贡献**：
- **10类细分体系**：将粗粒度4类扩展为层次化10类，精细刻画教学策略差异
- **层次化架构**：粗分类→细分类两层设计，提升识别准确率+6.1%，训练效率+28%
- **强风格区分度**：细粒度意图分布的区分指标0.15-0.28，显著高于粗粒度（0.08-0.12）

**定量结果**：
- **H-DAR vs 关键词规则**：宏平均F1从0.70提升至0.89（+27.1%）
- **H-DAR vs 单层BERT**：宏平均F1从0.84提升至0.89（+6.0%）
- **层次化 vs 扁平化**：细分类F1从0.82提升至0.87（+6.1%）

**教育学意义**：
- 10类细分体系能够有效区分"逻辑推导型"与"理论讲授型"等细微差异
- 为教学研究提供了量化工具，支持教学行为的精细分析

这些结果表明，**H-DAR是一项有效的改进**，生成的35维文本特征为后续的SHAPE跨模态融合提供了强判别力的输入。
