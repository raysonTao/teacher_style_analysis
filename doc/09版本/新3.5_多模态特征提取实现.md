## 3.5 多模态特征提取实现

本节介绍SHAPE引擎第二层（特征提取层）的具体实现，包括视觉、音频、文本三个模态的深度特征提取方法。

### 3.5.1 音频模态特征提取（Wav2Vec 2.0）

#### （1）深度声学表征

采用Wav2Vec 2.0预训练模型提取深度声学特征，相比传统MFCC具有更强的语义表达能力。

**输入**：16kHz采样的音频片段 $A \in \mathbb{R}^{N_s}$

**Wav2Vec 2.0提取**：
1. 卷积编码器：将原始波形转换为潜在表征
2. Transformer编码器：捕捉长距离依赖
3. 输出：768维特征向量 $F_{\text{wav2vec}} \in \mathbb{R}^{768}$

**全局统计特征**（10维）：
- 平均音量、音量标准差
- 基频均值、基频变化率
- 语速（词/分钟）
- 停顿频率、平均停顿时长

#### （2）情感分类头

在Wav2Vec 2.0基础上微调情感分类头，识别5类情感：

$$F_{\text{emotion}} = \text{softmax}(W_{\text{emo}}F_{\text{wav2vec}} + b_{\text{emo}}) \in \mathbb{R}^5$$

5类情感：neutral（中性）、happy（愉悦）、sad（低沉）、angry（激昂）、excited（激动）

#### （3）最终音频特征**（15维）**

$$F_a = [F_{\text{stats}}^{10}; F_{\text{emotion}}^{5}] \in \mathbb{R}^{15}$$

**vs MFCC的优势**（实验验证）：
- 单模态准确率：Wav2Vec 72.6% vs MFCC 66.2%（**+6.4%**）
- 噪声鲁棒性：SNR=10dB时，Wav2Vec 68.1% vs MFCC 56.8%（**+11.3%**）

### 3.5.2 视觉模态特征提取（DeepSORT + ST-GCN）

#### （1）教师检测与追踪

**Step 1：教师检测**

使用YOLOv8检测每帧中的教师位置：

$$\text{YOLOv8}(I_t) \to \{(x, y, w, h, \text{conf})\}_{\text{teacher}}$$

其中，$(x,y,w,h)$ 是边界框，$\text{conf}$ 是置信度。

**Step 2：教师追踪**

使用DeepSORT进行多帧追踪，保持教师ID稳定性：

$$\text{DeepSORT}(\{I_1, I_2, ..., I_T\}) \to \{\text{track}_{\text{teacher}}\}$$

**ID稳定性**：93.8% vs YOLO-only 68.3%（**+25.5%**）

#### （2）骨骼关键点提取

使用MediaPipe提取33个关键点：

$$\text{MediaPipe}(I_t) \to \mathbf{P}_t = \{(x_i, y_i, z_i)\}_{i=1}^{33}$$

**关键点类别**：
- 头部：5个（鼻子、眼睛、耳朵）
- 躯干：4个（肩膀、髋部）
- 上肢：10个（肘、腕、手指）
- 下肢：14个（膝、踝、脚趾）

#### （3）时空图卷积（ST-GCN）

将骨骼序列建模为时空图，提取动态特征：

**空间图**：33个节点，基于人体结构连接
**时间图**：连续帧之间的节点连接

**ST-GCN输出**：20维动作特征 $F_v \in \mathbb{R}^{20}$

**vs 单帧规则的优势**（实验验证）：
- 单模态准确率：ST-GCN 75.5% vs 单帧规则 57.8%（**+17.7%**）
- 捕捉动态：识别"巡视频率""手势强度"等时序特征

### 3.5.3 文本模态特征提取（BERT + H-DAR）

#### （1）ASR转写

使用Whisper Large-v3进行高质量转写：

**输入**：音频片段 $A$

**输出**：带时间戳的文本 $T = \{(w_1, t_1), (w_2, t_2), ..., (w_M, t_M)\}$

**CER（字错误率）**：平均3.2%（中文课堂场景）

#### （2）BERT语义编码

$$\mathbf{h}_{\text{BERT}} = \text{BERT}([CLS], w_1, ..., w_n, [SEP])$$

取[CLS]位置输出：$\mathbf{h}_s \in \mathbb{R}^{768}$

#### （3）H-DAR细粒度意图识别

通过层次化分类器识别10类细粒度意图（详见3.3节）：

$$\text{H-DAR}(\mathbf{h}_s) \to \mathbf{d}_{\text{act}} \in \mathbb{R}^{10}$$

#### （4）最终文本特征**（35维）**

$$F_t = [\mathbf{d}_{\text{act}}^{10}; \mathbf{d}_{\text{coarse}}^{4}; \mathbf{d}_{\text{2nd-order}}^{21}] \in \mathbb{R}^{35}$$

- 10维细分类频率
- 4维粗分类频率
- 21维二阶统计（意图共现矩阵上三角）

**vs 关键词规则的优势**（实验验证）：
- 单模态准确率：BERT+H-DAR 78.3% vs 关键词 65.7%（**+12.6%**）
- 意图识别F1：0.89 vs 0.70（**+0.19**）

### 本节小结

本节详细介绍了SHAPE引擎三模态特征提取的实现方法：

**音频模态（15维）**：
- Wav2Vec 2.0深度声学表征（10维统计特征 + 5维情感特征）
- vs MFCC提升6.4%单模态准确率

**视觉模态（20维）**：
- DeepSORT稳定追踪（ID稳定性93.8%）
- ST-GCN时空图卷积建模
- vs 单帧规则提升17.7%单模态准确率

**文本模态（35维）**：
- Whisper高质量ASR（CER 3.2%）
- BERT+H-DAR细粒度意图识别（10类）
- vs 关键词规则提升12.6%单模态准确率

三模态特征共**70维**，输入SHAPE融合模型，最终准确率91.4%（vs最佳单模态78.3%，提升13.1%），验证了深度特征提取和多模态融合的有效性。
